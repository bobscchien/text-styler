[basic]

seed = 24601

[data]

lang = zh
train_file = classical_chinese_pair

train_size = 35000
test_size = 3000
min_inp_len = 4
max_inp_len = 256
min_tar_len = 2
max_tar_len = 256

train_shard = 1
valid_shard = 1
test_shard = 1

[model]

inp_max = 256
tar_max = 64
bert_name = albert

# pretrained model
num_tune = 0
#nn_units = 64
#use_lstm = false

# downstream model
num_enc_layers = 2
num_dec_layers = 4
num_projection_layers = 1
embed_pos = true
embed_dim = 256
dense_dim = 512
num_heads = 8
dropout = 0.3
activation = gelu

[training]

# dataset
buffer_size = 35000
batch_size = 64

# training & validation
epochs = 100
earlystop = 5
teacher = 100
init_lr = 0.0005

# metric (bertscore, bleu, bleurt, coval, gleu, glue, meteor, rouge, sacrebleu, seqeval, squad, squad_v2, xnli)
metric_name = sacrebleu 

[inference]

beam_size = 3
beam_alpha = 0.6
topk = 3
topp = 0.9
temperature = 1.0
